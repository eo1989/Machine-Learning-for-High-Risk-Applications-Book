
# Code for Chapter 8 -  Debugging XGBoost
This chapter will introduce several methods, that go beyond traditional model assessment, to push models to their limits and find hidden problems and failure modes. The chapter starts with a concept refresher and then focuses on model debugging exercises that better simulate real-world stresses with sensitivity analysis and tests that uncover model errors with residual analysis. The overarching goal of model debugging is to increase trust in model performance with human users, but in the process, weâ€™ll also gain an increased level of transparency into models. 
# Code
1. Stress Testing [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/13TnzXm6kJuPt_kxcFmva6BLtL21oxZ0E?usp=sharing)   [![Open In GitHub](https://img.shields.io/badge/Github-code-green)](https://github.com/ml-for-high-risk-apps-book/Machine-Learning-for-High-Risk-Applications-Book/blob/main/code/Chapter-8/Stress_testing.ipynb)

2. Selecting a better XGBoost Model (https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/14GX0b4_xMDRZBmyibRGOk32iqr1OIDX4?usp=sharing)   [![Open In GitHub](https://img.shields.io/badge/Github-code-green)](https://github.com/ml-for-high-risk-apps-book/Machine-Learning-for-High-Risk-Applications-Book/blob/main/code/Chapter-8/Selecting_a_Better_XGBoost_Model.ipynb)